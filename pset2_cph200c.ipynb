{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b584d143-bfb9-4f07-af41-add00508e663",
   "metadata": {},
   "source": [
    "# Interpretability via SHAP Values \n",
    "\n",
    "CPH 200C Problem 2\n",
    "\n",
    "Questions? Ask Professor Irene Chen (iychen@berkeley.edu)\n",
    "\n",
    "As machine learning models become more inscrutable, we are interested in methods to better understand why our models make the decisions they do --- and as a result whether we can trust them. To address this problem, we typically apply either post-hoc explanations to trained models or restrict our models to specific classes that are deemed more easily understandable. The goal of this section of the problem set is to familiarize you with the SHAP values package to apply interpretability methods to the diabetes dataset we have already explored.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd52a54-cea3-4b6e-9de0-a2c4c2b74823",
   "metadata": {},
   "source": [
    "## 0. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e0175a-5d13-4b6a-806f-ac4d655b2781",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import xgboost\n",
    "import shap\n",
    "\n",
    "# TODO: change to location of unzipped csv files\n",
    "fname_adult_icu   = None\n",
    "fname_adult_notes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b07ccd1-e70a-4485-b57e-f0610c8818c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df    = pd.read_csv(fname_adult_icu)\n",
    "notes_df    = pd.read_csv(fname_adult_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b4600b-8aa8-4d3c-96ac-c6a351738139",
   "metadata": {},
   "source": [
    "## 1. Tabular Data From Clinical Data\n",
    "\n",
    "Below please find some simple data cleaning. You may substitute if you prefer your own data cleaning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced3697-4ee7-4323-aca0-1820e69ded48",
   "metadata": {},
   "outputs": [],
   "source": [
    "excl_col = set(['subject_id', 'hadm_id', 'icustay_id', 'mort_oneyr', 'mort_hosp',\n",
    "                'adult_icu', 'train', 'mort_icu', 'valid'])\n",
    "binary_col = set(['first_hosp_stay', 'first_icu_stay', 'adult_icu',\n",
    "       'eth_asian', 'eth_black', 'eth_hispanic', 'eth_other', 'eth_white',\n",
    "       'admType_ELECTIVE', 'admType_EMERGENCY', 'admType_NEWBORN',\n",
    "       'admType_URGENT'])\n",
    "target_col = 'mort_icu'\n",
    "zscore_col = [i for i in adult_df.columns if i not in excl_col and i not in binary_col]\n",
    "\n",
    "feature_col = [i for i in adult_df.columns if i not in excl_col]\n",
    "\n",
    "# We want to zscore the non-binary features\n",
    "adult_df[feature_col] = adult_df[feature_col].apply(zscore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61bba86-23c9-404e-80ce-21bd81b8bf62",
   "metadata": {},
   "source": [
    "Here we are training an XGBoost model to predict ICU mortality from the tabular MIMIC-III data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098cb3d4-b48d-4bce-826c-79bd6b56ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train/test split\n",
    "is_train = adult_df['train'] == 1\n",
    "is_test = adult_df['train'] == 0\n",
    "\n",
    "X = adult_df[feature_col]\n",
    "X_train = adult_df[is_train][feature_col]\n",
    "y_train = adult_df[is_train][target_col]\n",
    "\n",
    "X_test = adult_df[is_test][feature_col]\n",
    "y_test = adult_df[is_test][target_col]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "d_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "d_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Define parameters for the model\n",
    "params = {\n",
    "    \"eta\": 0.01,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y_train),\n",
    "    \"eval_metric\": \"logloss\",\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model = xgboost.train(\n",
    "    params,\n",
    "    d_train,\n",
    "    5000,\n",
    "    evals=[(d_test, \"test\")],\n",
    "    verbose_eval=100,\n",
    "    early_stopping_rounds=20,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfc3dc-e407-4f0a-b732-80cadfe0183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy_score from sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make predictions\n",
    "y_pred_prob = model.predict(d_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "X_display = X[feature_col]\n",
    "# Initialize JS visualization\n",
    "shap.initjs()\n",
    "\n",
    "# Explain the model's predictions using SHAP TreeExplainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "# TODO: Visualize the SHAP values for data point 100 using a force_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63eec82-bdca-4e98-b339-09e9047f01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Summarize the SHAP values with a summary plot \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c836b473-d401-4575-a642-9795cdad8ce4",
   "metadata": {},
   "source": [
    "## 2. Text Data From Clinical Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9102f7f2-ce03-47cb-861d-768ab3edcf1c",
   "metadata": {},
   "source": [
    "That was an example of how to use SHAP values to understand predictions from tabular data. Now let's explore how to visualize through clinical text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea66cec-16e5-458a-9e51-a96c9385366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = 'chartext'\n",
    "target_col = 'mort_oneyr'\n",
    "\n",
    "ctxt = notes_df[feature_col]\n",
    "vec = TfidfVectorizer(max_features=500,stop_words='english')\n",
    "\n",
    "vec = vec.fit(ctxt)\n",
    "\n",
    "is_train = notes_df['train'] == 1\n",
    "is_test = notes_df['train'] == 0\n",
    "\n",
    "X_train = normalize(vec.transform(notes_df[is_train][feature_col]), norm='l1', axis=0)\n",
    "y_train = notes_df[is_train][target_col]\n",
    "\n",
    "X_test = normalize(vec.transform(notes_df[is_test][feature_col]), norm='l1', axis=0)\n",
    "y_test = notes_df[is_test][target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea1a7a-156e-47f5-a2b2-5b555abee0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP \n",
    "model = LinearSVC().fit(X_train, y_train)\n",
    "\n",
    "# Create explainer\n",
    "explainer = shap.LinearExplainer(model, X_train)\n",
    "\n",
    "# Generate SHAP values\n",
    "text_to_explain = \"Pt is worsening with liver failure, will transfer to surgery\"\n",
    "x = vec.transform([text_to_explain])\n",
    "\n",
    "# Convert sparse matrix to dense array\n",
    "x_dense = x.toarray()\n",
    "\n",
    "# Generate SHAP values for the dense array\n",
    "shap_values = explainer.shap_values(x_dense)\n",
    "\n",
    "# TODO: Visualize the text_to_explain using a force plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0661b498-3207-47f8-8fb6-7213efaf5e3a",
   "metadata": {},
   "source": [
    "Because of the TFIDF vectorization, the string names aren't obvious. Use this dictionary to plug in feature numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16903a67-6512-4553-a2a1-da0b257bf325",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num_name_dict = {i:j for i,j in enumerate(vec.get_feature_names_out())}\n",
    "\n",
    "# example: feature 200\n",
    "print(feature_num_name_dict[200])\n",
    "\n",
    "# TODO: What are the features increasing the likelihood of ICU mortality in the text_to_explain string?\n",
    "\n",
    "# TODO: What are the features decreasing the likelihood of ICU mortality in the text_to_explain string?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
